(window.webpackJsonp=window.webpackJsonp||[]).push([[58],{400:function(a,t,e){"use strict";e.r(t);var s=e(1),r=Object(s.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"消息队列-message-queue"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息队列-message-queue"}},[a._v("#")]),a._v(" 消息队列（Message Queue)")]),a._v(" "),t("h2",{attrs:{id:"_1-mq概念"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-mq概念"}},[a._v("#")]),a._v(" 1.MQ概念")]),a._v(" "),t("h2",{attrs:{id:"_2-消息队列分类"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-消息队列分类"}},[a._v("#")]),a._v(" 2.消息队列分类")]),a._v(" "),t("h2",{attrs:{id:"_3-消息队列mq对比"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-消息队列mq对比"}},[a._v("#")]),a._v(" 3.消息队列MQ对比")]),a._v(" "),t("h3",{attrs:{id:"mq概念"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mq概念"}},[a._v("#")]),a._v(" MQ概念")]),a._v(" "),t("blockquote",[t("p",[a._v("MQ模型\n"),t("img",{attrs:{src:"https://gitee.com/nylg/picture/raw/master/kafka/1.png",alt:""}}),a._v("\n解耦合\n提高系统的响应时间")])]),a._v(" "),t("h3",{attrs:{id:"消息队列分类"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息队列分类"}},[a._v("#")]),a._v(" 消息队列分类")]),a._v(" "),t("blockquote",[t("p",[a._v("点对点:\n消息生产者生产消息发送到queue中，然后消息消费者从queue中取出并且消费消息。")]),a._v(" "),t("blockquote",[t("p",[a._v("注意：\n消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。\nQueue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。")])])]),a._v(" "),t("blockquote",[t("p",[a._v("发布/订阅:\n消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费。")])]),a._v(" "),t("h3",{attrs:{id:"消息队列mq对比"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息队列mq对比"}},[a._v("#")]),a._v(" 消息队列MQ对比")]),a._v(" "),t("blockquote",[t("p",[a._v("RabbitMQ：支持的协议多，非常重量级消息队列，对路由(Routing)，负载均衡(Load balance)或者数据持久化都有很好的支持。\nZeroMQ：号称最快的消息队列系统，尤其针对大吞吐量的需求场景，擅长的高级/复杂的队列，但是技术也复杂，并且只提供非持久性的队列。\nActiveMQ：Apache下的一个子项，类似ZeroMQ，能够以代理人和点对点的技术实现队列 。\nRedis：是一个key-Value的NOSql数据库，但也支持MQ功能，数据量较小，性能优于RabbitMQ，数据超过10K就慢的无法忍受")])]),a._v(" "),t("h1",{attrs:{id:"kafka介绍"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka介绍"}},[a._v("#")]),a._v(" Kafka介绍")]),a._v(" "),t("h2",{attrs:{id:"_1-概念"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-概念"}},[a._v("#")]),a._v(" 1.概念")]),a._v(" "),t("h2",{attrs:{id:"_2-特点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-特点"}},[a._v("#")]),a._v(" 2.特点")]),a._v(" "),t("h2",{attrs:{id:"_3-测试效果"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-测试效果"}},[a._v("#")]),a._v(" 3.测试效果")]),a._v(" "),t("h3",{attrs:{id:"概念"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#概念"}},[a._v("#")]),a._v(" 概念")]),a._v(" "),t("blockquote",[t("p",[a._v("Kafka 是分布式发布-订阅消息系统。它最初由 LinkedIn 公司开发，使用 Scala语言编写,之后成为 Apache 项目的一部分。Kafka 是一个分布式的，可划分的，多订阅者,冗余备份的持久性的日志服务。它主要用于处理活跃的流式数据。")])]),a._v(" "),t("h3",{attrs:{id:"特点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#特点"}},[a._v("#")]),a._v(" 特点")]),a._v(" "),t("blockquote",[t("p",[a._v("1,同时为发布和订阅提供高吞吐量。据了解，Kafka 每秒可以生产约 25 万消息（50 MB），每秒处理 55 万消息（110 MB）。\n2,可进行持久化操作。将消息持久化到磁盘，因此可用于批量消费，例如 ETL，以及实时应用程序。通过将数据持久化到硬盘以及 replication 防止数据丢失。\n3,分布式系统，易于向外扩展。所有的 producer、broker 和 consumer 都会有多个，均为分布式的。无需停机即可扩展机器。\n4,消息被处理的状态是在 consumer 端维护，而不是由 server 端维护。当失败时能自动平衡。\n5,支持 online 和 offline 的场景。")])]),a._v(" "),t("h3",{attrs:{id:"测试效果"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#测试效果"}},[a._v("#")]),a._v(" 测试效果")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/nylg/picture/raw/master/kafka/2.png",alt:""}})]),a._v(" "),t("h1",{attrs:{id:"kafka逻辑架构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka逻辑架构"}},[a._v("#")]),a._v(" Kafka逻辑架构")]),a._v(" "),t("h2",{attrs:{id:"_1-核心架构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-核心架构"}},[a._v("#")]),a._v(" 1.核心架构")]),a._v(" "),t("h2",{attrs:{id:"_2-核心概念"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-核心概念"}},[a._v("#")]),a._v(" 2.核心概念")]),a._v(" "),t("h3",{attrs:{id:"核心架构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#核心架构"}},[a._v("#")]),a._v(" 核心架构")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/nylg/picture/raw/master/kafka/3.png",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"核心概念"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#核心概念"}},[a._v("#")]),a._v(" 核心概念")]),a._v(" "),t("blockquote",[t("p",[a._v("Producer 特指消息的生产者\nConsumer 特指消息的消费者\nConsumer Group 消费者组，可以并行消费Topic中partition的消息\nBroker：缓存代理，Kafa 集群中的一台或多台服务器统称为 broker。\nTopic：特指 Kafka 处理的消息源（feeds of messages）的不同分类。\nPartition：Topic 物理上的分组，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。partition 中的每条消息都会被分配一个有序的 id（offset）。\nMessage：消息，是通信的基本单位，每个 producer 可以向一个 topic（主题）发布一些消息。\nProducers：消息和数据生产者，向 Kafka 的一个 topic 发布消息的过程叫做 producers。\nConsumers：消息和数据消费者，订阅 topics 并处理其发布的消息的过程叫做 consumers。")])]),a._v(" "),t("blockquote",[t("p",[a._v("Kafka的Producers")]),a._v(" "),t("blockquote",[t("p",[a._v('1.消息和数据生产者，向 Kafka 的一个 topic 发布消息的过程叫做 producers。\n2.Producer将消息发布到指定的Topic中,同Producer也能决定将此消息归属于哪个partition;比如基于"round-robin"方式或者通过其他的一些算法等.\n3.异步发送\n批量发送可以很有效的提高发送效率。Kafka producer的异步发送模式允许进行批量发送，先将消息缓存在内存中，然后一次请求批量发送出去')])])]),a._v(" "),t("blockquote",[t("p",[a._v("Kafka的Broker")]),a._v(" "),t("blockquote",[t("p",[a._v("1.Broker：缓存代理，Kafka 集群中的一台或多台服务器统称为 broker。\n2.Message在Broker中通Log追加的方式进行持久化存储。并进行分区（patitions)\n3.为了减少磁盘写入的次数,broker会将消息暂时buffer起来,当消息的个数(或尺寸)达到一定阀值时,再flush到磁盘,这样减少了磁盘IO调用的次数")])])]),a._v(" "),t("blockquote",[t("p",[a._v("Kafka的Broker无状态机制")]),a._v(" "),t("blockquote",[t("p",[a._v("1.Broker没有副本机制，一旦broker宕机，该broker的消息将都不可用。\n2.Broker不保存订阅者的状态，由订阅者自己保存。\n3.无状态导致消息的删除成为难题（可能删除的消息正在被订阅），kafka采用基于时间的SLA(服务水平保证)，消息保存一定时间（通常为7天）后会被删除。\n4.消息订阅者可以rewind back到任意位置重新进行消费，当订阅者故障时，可以选择最小的offset(id)进行重新读取消费消息。")])])]),a._v(" "),t("blockquote",[t("p",[a._v("Kafka的Message组成")]),a._v(" "),t("blockquote",[t("p",[a._v("1.Message消息：是通信的基本单位，每个 producer 可以向一个 topic（主题）发布一些消息。\n2.Kafka中的Message是以topic为基本单位组织的，不同的topic之间是相互独立的。每个topic又可以分成几个不同的partition(每个topic有几个partition是在创建topic时指定的)，每个partition存储一部分Message。\n3.partition中的每条Message包含了以下三个属性：")]),a._v(" "),t("blockquote",[t("p",[a._v("offset\t对应类型：long\nMessageSize\t对应类型：int32\ndata\t\t是message的具体内容")])])])]),a._v(" "),t("blockquote",[t("p",[a._v("Kafka的Partitions分区的目的")]),a._v(" "),t("blockquote",[t("p",[a._v("1.kafka基于文件存储.通过分区,可以将日志内容分散到多个server上,来避免文件尺寸达到单机磁盘的上限,每个partiton都会被当前server(kafka实例)保存;\n2.可以将一个topic切分多任意多个partitions,来消息保存/消费的效率.\n3.越多的partitions意味着可以容纳更多的consumer,有效提升并发消费的能力.")])])]),a._v(" "),t("blockquote",[t("p",[a._v("Kafka的Consumers")]),a._v(" "),t("blockquote",[t("p",[a._v("1.消息和数据消费者，订阅 topics 并处理其发布的消息的过程叫做 consumers。\n2.在 kafka中,我们 可以认为一个group是一个“订阅者”,一个Topic中的每个partions,只会被一个“订阅者”中的一个consumer消费,不过一个 consumer可以消费多个partitions中的消息（消费者数据小于Partions的数量时）")]),a._v(" "),t("blockquote",[t("p",[a._v("注： kafka的设计原理决定,对于一个topic,同一个group中不能有多于partitions个数的consumer同时消费,否则将意味着某些consumer将无法得到消息.\n"),t("img",{attrs:{src:"https://gitee.com/nylg/picture/raw/master/kafka/4.png",alt:""}})])])])]),a._v(" "),t("h1",{attrs:{id:"kafka的持久化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka的持久化"}},[a._v("#")]),a._v(" Kafka的持久化")]),a._v(" "),t("blockquote",[t("p",[a._v("数据持久化：")]),a._v(" "),t("blockquote",[t("p",[a._v("发现线性的访问磁盘，很多时候比随机的内存访问快得多\n传统的使用内存做为磁盘的缓存\nKafka直接将数据写入到日志文件中")])])]),a._v(" "),t("blockquote",[t("p",[a._v("日志数据持久化特性：")]),a._v(" "),t("blockquote",[t("p",[a._v("写操作：通过将数据追加到文件中实现\n读操作：读的时候从文件中读就好了")])])]),a._v(" "),t("blockquote",[t("p",[a._v("优势：读操作不会阻塞写操作和其他操作，数据大小不对性能产生影响；\n没有容量限制（相对于内存来说）的硬盘空间建立消息系统；\n线性访问磁盘，速度快，可以保存任意一段时间")])]),a._v(" "),t("blockquote",[t("p",[a._v("一个Topic可以认为是一类消息，每个topic将被分成多partition(区),每个partition在存储层面是append log文件。任何发布到此partition的消息都会被直接追加到log文件的尾部，每条消息在文件中的位置称为offset（偏移量）,partition是以文件的形式存储在文件系统中。\nLogs文件根据broker中的配置要求,保留一定时间后删除来释放磁盘空间。\n"),t("img",{attrs:{src:"https://gitee.com/nylg/picture/raw/master/kafka/5.png",alt:""}}),a._v("\nPartition：\nTopic 物理上的分组，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。   \tpartition 中的每条消息都会被分配一个有序的 id（offset)。")])]),a._v(" "),t("blockquote",[t("p",[a._v("为数据文件建索引：稀疏存储，每隔一定字节的数据建立一条索引。\v下图为一个partition的索引示意图："),t("img",{attrs:{src:"https://gitee.com/nylg/picture/raw/master/kafka/6.png",alt:""}})])]),a._v(" "),t("h1",{attrs:{id:"kafka的分布式实现"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka的分布式实现"}},[a._v("#")]),a._v(" Kafka的分布式实现")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/nylg/picture/raw/master/kafka/7.png",alt:""}}),a._v(" "),t("img",{attrs:{src:"https://gitee.com/nylg/picture/raw/master/kafka/8.png",alt:""}})]),a._v(" "),t("h1",{attrs:{id:"kafka的通讯协议"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka的通讯协议"}},[a._v("#")]),a._v(" Kafka的通讯协议")]),a._v(" "),t("blockquote",[t("p",[a._v("Kafka的Producer、Broker和Consumer之间采用的是一套自行设计基于TCP层的协议，根据业务需求定制，而非实现一套类似Protocol Buffer的通用协议。")])]),a._v(" "),t("blockquote",[t("p",[a._v("基本数据类型：")]),a._v(" "),t("blockquote",[t("p",[a._v("1.定长数据类型：int8,int16,int32和int64，对应到Java中就是byte, short, int和long。\n2.变长数据类型：bytes和string。变长的数据类型由两部分组成，分别是一个有符号整数N(表示内容的长度)和N个字节的内容。其中，N为-1表示内容为null。bytes的长度由int32表示，string的长度由int16表示。\n3.数组：数组由两部分组成，分别是一个由int32类型的数字表示的数组长度N和N个元素。")])])]),a._v(" "),t("blockquote",[t("p",[a._v("Kafka通讯的基本单位是Request/Response\n基本结构：\nRequestOrResponse => MessageSize (RequestMessage | ResponseMessage)\n"),t("img",{attrs:{src:"https://gitee.com/nylg/picture/raw/master/kafka/9.png",alt:""}}),a._v("\n通讯过程：")]),a._v(" "),t("blockquote",[t("p",[a._v("客户端打开与服务器端的Socket\n往Socket写入一个int32的数字(数字表示这次发送的Request有多少字节)\n服务器端先读出一个int32的整数从而获取这次Request的大小\n然后读取对应字节数的数据从而得到Request的具体内容\n服务器端处理了请求后，也用同样的方式来发送响应。")])])]),a._v(" "),t("blockquote",[t("p",[a._v("RequestMessage结构:\nRequestMessage => ApiKey ApiVersion CorrelationId ClientId Request\n"),t("img",{attrs:{src:"https://gitee.com/nylg/picture/raw/master/kafka/10.png",alt:""}})])]),a._v(" "),t("blockquote",[t("p",[a._v("ResponseMessage结构:\nResponseMessage => CorrelationId Response\n"),t("img",{attrs:{src:"https://gitee.com/nylg/picture/raw/master/kafka/11.png",alt:""}}),a._v("\nKafka采用是经典的Reactor(同步IO)模式，也就是1个Acceptor响应客户端的连接请求，N个Processor来读取数据，这种模式可以构建出高 性能的服务器。")])]),a._v(" "),t("blockquote",[t("p",[a._v("Message:Producer生产的消息,键-值对\nMessage => Crc MagicByte Attributes Key Value\n"),t("img",{attrs:{src:"https://gitee.com/nylg/picture/raw/master/kafka/12.png",alt:""}})])]),a._v(" "),t("blockquote",[t("p",[a._v("MessageSet:用来组合多条Message，它在每条Message的基础上加上了Offset和MessageSize\nMessageSet => [Offset MessageSize Message]\n"),t("img",{attrs:{src:"https://gitee.com/nylg/picture/raw/master/kafka/13.png",alt:""}})])]),a._v(" "),t("blockquote",[t("p",[a._v("Request/Respone和Message/MessageSet的关系：\n"),t("img",{attrs:{src:"https://gitee.com/nylg/picture/raw/master/kafka/14.png",alt:""}})]),a._v(" "),t("blockquote",[t("p",[a._v("备注：Kafka的通讯协议中不含Schema，格式也比较简单，这样设计的好处是协议自身的Overhead小，再加上把多条Message放在一起做压缩，提高压缩比率，从而在网络上传输的数据量会少一些。")])])]),a._v(" "),t("h1",{attrs:{id:"kafka数据传输的事务定义"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka数据传输的事务定义"}},[a._v("#")]),a._v(" Kafka数据传输的事务定义")]),a._v(" "),t("blockquote",[t("p",[a._v('1.at most once: 最多一次,这个和JMS中"非持久化"消息类似.发送一次,无论成败,将不会重发.\n2.at least once: 消息至少发送一次,如果消息未能接受成功,可能会重发,直到接收成功.\n3.exactly once: 消息只会发送一次.')]),a._v(" "),t("blockquote",[t("p",[a._v('1.at most once: 消费者fetch消息,然后保存offset,然后处理消息;当client保存offset之后,但是在消息处理过程中出现了异常,导致部分消息未能继续处理.那么此后"未处理"的消息将不能被fetch到,这就是"at most once".\n2.at least once: 消费者fetch消息,然后处理消息,然后保存offset.如果消息处理成功之后,但是在保存offset阶段zookeeper异常导致保存操作未能执行成功,这就导致接下来再次fetch时可能获得上次已经处理过的消息,这就是"at least once"，原因offset没有及时的提交给zookeeper，zookeeper恢复正常还是之前offset状态.\n3.exactly once: kafka中并没有严格的去实现(基于2阶段提交,事务),我们认为这种策略在kafka中是没有必要的.')])]),a._v(" "),t("blockquote",[t("blockquote",[t("p",[a._v('注：通常情况下"at-least-once"是我们首选.(相比at most once而言,重复接收数据总比丢失数据要好).')])])])]),a._v(" "),t("h1",{attrs:{id:"kafka使用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka使用"}},[a._v("#")]),a._v(" Kafka使用")]),a._v(" "),t("h2",{attrs:{id:"_1-kafka安装"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-kafka安装"}},[a._v("#")]),a._v(" 1.Kafka安装")]),a._v(" "),t("h2",{attrs:{id:"_2-kafka客户端操作"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-kafka客户端操作"}},[a._v("#")]),a._v(" 2.Kafka客户端操作")]),a._v(" "),t("h2",{attrs:{id:"_3-kafka集群安装"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-kafka集群安装"}},[a._v("#")]),a._v(" 3.kafka集群安装")]),a._v(" "),t("h2",{attrs:{id:"_4-kafka-java操作"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-kafka-java操作"}},[a._v("#")]),a._v(" 4.kafka java操作")]),a._v(" "),t("h3",{attrs:{id:"kafka安装"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka安装"}},[a._v("#")]),a._v(" kafka安装")]),a._v(" "),t("blockquote",[t("p",[a._v('下载\nhttp://kafka.apache.org/downloads.html\n解压\ntar -zxvf kafka_2.10-0.8.1.1.tgz\n启动服务\n首先启动zookeeper服务\nbin/zookeeper-server-start.sh config/zookeeper.properties\n启动Kafka\nbin/kafka-server-start.sh config/server.properties >/dev/null 2>&1 &\n创建topic\n创建一个"test"的topic，一个分区一个副本\nbin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n查看主题\nbin/kafka-topics.sh --list --zookeeper localhost:2181\n查看主题详情\nbin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test\n删除主题\nbin/kafka-run-class.sh kafka.admin.TopicCommand –delete --topic test --zookeeper 192.168.1.161:2181')])]),a._v(" "),t("h3",{attrs:{id:"kafka客户端操作"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka客户端操作"}},[a._v("#")]),a._v(" Kafka客户端操作")]),a._v(" "),t("blockquote",[t("p",[a._v("创建生产者 producer\nbin/kafka-console-producer.sh --broker-list localhost:9092 --topic test\n创建消费者 consumer\nbin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning")]),a._v(" "),t("blockquote",[t("p",[a._v("参数使用帮组信息查看：\n生产者参数查看：bin/kafka-console-producer.sh\n消费者参数查看：bin/kafka-console-consumer.sh")])])]),a._v(" "),t("h3",{attrs:{id:"kafka集群安装"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka集群安装"}},[a._v("#")]),a._v(" kafka集群安装")]),a._v(" "),t("blockquote",[t("p",[a._v("安装zk集群\n修改配置文件详情\nbroker.id：   唯一，填数字\nhost.name：唯一，填服务器\nzookeeper.connect=192.168.40.134:2181,192.168.40.132:2181,192.168.40.133:2181")])]),a._v(" "),t("h3",{attrs:{id:"kafka-java操作"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka-java操作"}},[a._v("#")]),a._v(" kafka java操作")]),a._v(" "),t("blockquote",[t("p",[a._v("生产者\n消费者")])]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("pom依赖\n<dependency>\n     <groupId>org.apache.kafka</groupId>\n     <artifactId>kafka_2.10</artifactId>\n     <version>0.8.2.0</version>\n</dependency>\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br")])])])}),[],!1,null,null,null);t.default=r.exports}}]);